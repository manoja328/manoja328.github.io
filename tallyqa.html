<html>
<head>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,500,700|Crete+Round" rel="stylesheet" type="text/css">
<meta charset="UTF-8">
    
    <style>
body {
    font-family: 'Roboto', sans-serif;
    font-weight: 300;
    width: 800px;
    color: #333;
    margin: auto;
}
        
        div {
    text-align: justify;
    text-justify: inter-word;
}
        
</style>
    
</head>
<body>
<title>tallyqa</title>
<h2><center>TallyQA: Answering Complex Counting Questions</center> </h2>
<div >
Recently computer vision has begun to develop algorithms for open-ended counting. These systems take in a counting question and an image and predict a whole number that answers the question. While object recognition systems now rival humans, today’s best open-ended counting systems perform poorly. This could be due to an inability to detect the correct objects or due to an inability to reason about them. To address this, we distinguish between simple and complex counting questions. Simple counting questions only require object detection, e.g., “How many dogs are there?” Complex questions require deeper analysis, e.g., “How many dogs are eating?”. <br><br>

Majority of counting questions in Visual Question Answering (VQA) datasets such as VQA1.0 , VQA2.0, TDIUC, etc. are simple and can be easily answered using an object detector.  Complex counting questions involve understanding relationships between objects along with their attributes and require more reasoning . Thus, performance of counting models can only be truly evaluated based on perfromance on complex couting questions. So, we have developed TallyQA dataset that has both simple and complex questions. TallyQA is also the largest counting dataset to our knowledge, having 287,907 questions and  165,443 images. To get the best quality questions, we collected 19.5K complex questions using Amazon Mechanical Turk(AMT).<br><br>


 For learning to count we propose the relational counting network (RCN), a new algorithm for counting that infers relationships between objects and background image regions. It is inspired by relation networks, with modifications to handle a dynamic number of image regions and to explicitly incorporate background information. 


    
    
     <img src="https://raw.githubusercontent.com/manoja328/manoja328.github.io/master/RCN.jpg" class="img-responsive center-block"> <br>
    
Our RCN model computes the relationship between foreground regions as well as the relationships between the these regions and the background to efficiently answer complex counting questions. In this example, the system needs to look at the relationship of each giraffe to each other and with the water (background).
    
</div>
    
<h3>Paper and dataset download links will be released soon...</h3>



<h2>Contact</h2>
Please feel free to contact about any question regarding the dataset.<br><br>


                <div class="row">
                    
                                            <div class="col-sm-3 text-center">
        <a href="http://www.kushalkafle.com/" target="_blank"><img src="http://www.manojacharya.com/profile-pic.jpeg" class="img-circle center-block " alt="Manoj Acharya" height="200" width="200"></a>
                            <a href="http://www.manojacharya.com/"><h3>Manoj Acharya</h3></a>
                            <p> Ph.D. Student <br>
                            Chester F. Carlson Center for Imaging Science<br>
                                Rochester Institute of Technology
                            </p>

      </div>
                    
                    
                    
    <div class="col-sm-3 col-sm-offset-1 text-center">
        <a href="http://www.kushalkafle.com/" target="_blank"><img src="https://kushalkafle.com/images/kushal.jpg" class="img-circle center-block " alt="Kushal Kafle" height="200"></a>
                            <a href="http://www.kushalkafle.com/"><h3>Kushal Kafle</h3></a>
                            <p> Ph.D. Student <br>
                            Chester F. Carlson Center for Imaging Science<br>
                                Rochester Institute of Technology
                            </p>

      </div>
 

                    
     <div class="col-sm-3  col-sm-offset-1 text-center">        
<a href="http://chriskanan.com" target="_blank"><img src="https://kushalkafle.com/images/chris-rit.jpg" class="img-circle center-block" alt="Christopher Kanan" height="200">
        <h3>Christopher Kanan</h3></a>
                            <p> Assistant Professor <br>
                            Chester F. Carlson Center for Imaging Science<br>
                                Rochester Institute of Technology
                            </p>
      </div>
    </div>

    </body>
</html>
    
