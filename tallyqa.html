<html>
<head>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,500,700|Crete+Round" rel="stylesheet" type="text/css">
<meta charset="UTF-8">
    
    <style>
body {
    font-family: 'Roboto', sans-serif;
    font-weight: 300;
    width: 800px;
    color: #333;
    margin: auto;
}
        
        div {
    text-align: justify;
    text-justify: inter-word;
}
        
</style>
    
</head>
<body>
<title>tallyqa</title>
<h2><center>TallyQA: Answering Complex Counting Questions</center> </h2>
<div >
Computer vision has begun to develop algorithms for open-ended counting. These systems take in a "How many...?" question and an image and predict a whole number that answers the question. While object recognition systems now rival humans, today's best open-ended counting systems perform poorly. This could be due to an inability to detect the correct objects or due to an inability to reason about them. To address this, we distinguish between simple and complex counting questions. Simple counting questions only require object detection, e.g., “How many dogs are there?” Complex questions require deeper analysis, e.g., “How many dogs are eating?”. <br><br>

Most counting questions in Visual Question Answering (VQA) datasets (e.g., VQA 1.0 , VQA 2.0, and TDIUC) are simple and can be easily answered using an object detector. Complex counting questions involve understanding relationships between objects along with their attributes and require more reasoning. Thus, performance of counting models cannot be estimated on complex counting questions using these datasets. To address this, we created the TallyQA dataset that has both simple and complex questions. TallyQA is the largest counting dataset to our knowledge, having 287,907 questions and 165,443 images. To get the best quality questions, we collected 19.5K complex questions using Amazon Mechanical Turk (AMT).<br><br>

    TallyQA has both simple counting questions that require only object detection and complex counting questions that demand more, as shown by the example image below. 
<img src="https://raw.githubusercontent.com/manoja328/manoja328.github.io/master/simp_comp.jpg" class="img-responsive center-block"> <br>
    
 For learning to count we propose the relational counting network (RCN), a new algorithm for counting that infers relationships between objects and background image regions. It is inspired by relation networks, with modifications to handle a dynamic number of image regions and to explicitly incorporate background information.

    
    
     <img src="https://raw.githubusercontent.com/manoja328/manoja328.github.io/master/RCN.jpg" class="img-responsive center-block"> <br>
    
Our RCN model computes the relationship between foreground regions as well as the relationships between the these regions and the background to efficiently answer complex counting questions. In this example, the system needs to look at the relationship of each giraffe to each other and with the water (background).
    
</div>
    
<h3>Paper and dataset download links will be released in Fall 2018.</h3>



<h2>Contact</h2>
<br>


                <div class="row">
                    
                                            <div class="col-sm-3 text-center">
        <a href="http://www.kushalkafle.com/" target="_blank"><img src="http://www.manojacharya.com/profile-pic.jpeg" class="img-circle center-block " alt="Manoj Acharya" height="200" width="200"></a>
                            <a href="http://www.manojacharya.com/"><h3>Manoj Acharya</h3></a>
                            <p> Ph.D. Student <br>
                            Chester F. Carlson Center for Imaging Science<br>
                                Rochester Institute of Technology
                            </p>

      </div>
                    
                    
                    
    <div class="col-sm-3 col-sm-offset-1 text-center">
        <a href="http://www.kushalkafle.com/" target="_blank"><img src="https://kushalkafle.com/images/kushal.jpg" class="img-circle center-block " alt="Kushal Kafle" height="200"></a>
                            <a href="http://www.kushalkafle.com/"><h3>Kushal Kafle</h3></a>
                            <p> Ph.D. Student <br>
                            Chester F. Carlson Center for Imaging Science<br>
                                Rochester Institute of Technology
                            </p>

      </div>
 

                    
     <div class="col-sm-3  col-sm-offset-1 text-center">        
<a href="http://chriskanan.com" target="_blank"><img src="https://kushalkafle.com/images/chris-rit.jpg" class="img-circle center-block" alt="Christopher Kanan" height="200">
        <h3>Christopher Kanan</h3></a>
                            <p> Assistant Professor <br>
                            Chester F. Carlson Center for Imaging Science<br>
                                Rochester Institute of Technology
                            </p>
      </div>
    </div>

    </body>
</html>
    
