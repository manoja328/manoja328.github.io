

<html>
<head>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,500,700|Crete+Round" rel="stylesheet" type="text/css">
<meta charset="UTF-8">
    
    <style>
body {
    font-family: 'Roboto', sans-serif;
    font-weight: 300;
    width: 800px;
    color: #333;
    margin: auto;
}
        
        div {
    text-align: justify;
    text-justify: inter-word;
}
        
</style>
    
</head>
<body>
<title>TallyQA</title>
<h2><center>TallyQA: Answering Complex Counting Questions</center> </h2>


<div >
Computer vision has begun to develop algorithms for open-ended counting. These systems take in a "How many...?" question and an image and predict a whole number that answers the question. While object recognition systems now rival humans, today's best open-ended counting systems perform poorly. This could be due to an inability to detect the correct objects or due to an inability to reason about them. To address this, we distinguish between simple and complex counting questions. Simple counting questions only require object detection, e.g., "How many dogs are there?" Complex questions require deeper analysis, e.g., "How many dogs are eating?" <br><br>

Most counting questions in Visual Question Answering (VQA) datasets (e.g., VQA 1.0 , VQA 2.0, and TDIUC) are simple and can be easily answered using an object detector. Complex counting questions involve understanding relationships between objects along with their attributes and require more reasoning. Thus, performance of counting models cannot be estimated on complex counting questions using these datasets. To address this, we created the TallyQA dataset that has both <b>simple</b> and <b>complex</b> questions.

   Simple counting questions are those which require only object detection whereas complex counting questions demand more, as shown by the example image below. 
<img src="https://raw.githubusercontent.com/manoja328/manoja328.github.io/master/simp_comp.jpg" class="img-responsive center-block"> <br>
<div class="alert alert-info">
Many questions in the previous VQA datasets look complex but easy to answer even using an off-the-shelf object detection system. For e.g., "How many men are wearing glasses?" is not difficult if all of the men in the image are wearing glasses. To ensure that we get quality complex questions, annotators were told to ask questions in which there were counter examples, e.g., to ask "How many men are wearing glasses?" only if it had an answer greater than zero, and the contrary question "How many men are <em>not</em> wearing glasses?" had an answer greater than zero.<br>   
The distinction can also be understood by the following examples.<br>
    <img src="https://raw.githubusercontent.com/manoja328/manoja328.github.io/master/assets/simpcompeg.jpg" class="img-responsive center-block"> <br>
    </div>
    
    <h2>TallyQA Stats</h2>
    As of Nov. 2018, TallyQA is the <b>largest open-ended counting dataset</b> for VQA. It is also the only dataset to distinguish between simple and complex counting questions. In summary, it has
<ul>
    <li>287K questions</li>
    <li>165K images</li>
    <li> 19K complex questions collected from human annotators using AMT</li>
</ul>        
</div>
    

<h3><a href="https://arxiv.org/abs/1801.08163">Click here to read more about TallyQA and our algorithm in our AAAI-2019 paper.</a></h3>


<h3>The TallyQA dataset can be obtained from  <a href="https://github.com/manoja328/tallyqa">our Github repo</a>.</h3>
If you use TallyQA in your work, please cite it as follows:
<pre><code>
 @inproceedings{acharya2019tallyqa,
  title={TallyQA: Answering Complex Counting Questions},
  author={Acharya, Manoj and Kafle, Kushal and Kanan, Christopher},
  booktitle={AAAI},
  year={2019}}
    </code></pre>
<h2>Contact</h2>
<br>


                <div class="row">
                    
   <div class="col-md-4 text-center">
        <a href="http://www.manojacharya.com/" target="_blank"><img src="https://raw.githubusercontent.com/manoja328/manoja328.github.io/master/profile-pic.jpeg" class="img-circle center-block " alt="Manoj Acharya" height="200" ></a>
                            <a href="http://www.manojacharya.com/"><h3>Manoj Acharya</h3></a>


      </div>
                    
                    
                    
    <div class="col-md-4  text-center">
        <a href="http://www.kushalkafle.com/" target="_blank"><img src="https://kushalkafle.com/images/kushal.jpg" class="img-circle center-block " alt="Kushal Kafle" height="200"></a>
                            <a href="http://www.kushalkafle.com/"><h3>Kushal Kafle</h3></a>


      </div>
 

                    
     <div class="col-md-4  text-center">        
<a href="http://chriskanan.com" target="_blank"><img src="https://kushalkafle.com/images/chris-rit.jpg" class="img-circle center-block" alt="Prof. Christopher Kanan" height="200">
        <h3>Christopher Kanan</h3></a>
                          
						  
      </div>
    </div>

    </body>
</html>
    
